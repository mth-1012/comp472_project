{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90cfadf3",
   "metadata": {},
   "source": [
    "# AI Face Mask Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77d9c2b",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d0383",
   "metadata": {},
   "source": [
    "Import libraries and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fe52ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from skorch import NeuralNetClassifier\n",
    "# from skorch.helper import SliceDataset\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import (make_scorer, accuracy_score, \n",
    "                        precision_score, recall_score, f1_score)\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6eef82",
   "metadata": {},
   "source": [
    "Transform methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da262ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.Resize(32),\n",
    "    transforms.CenterCrop(32),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbc57b",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d004d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "classes = ('cloth', 'n95', 'none', 'surgical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d78680c",
   "metadata": {},
   "source": [
    "Device to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fca4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c911ab",
   "metadata": {},
   "source": [
    "## CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17cb780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1000, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2695ce",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8524c1a",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(root='./data/dataset/', transform=transform)\n",
    "\n",
    "m = len(dataset)\n",
    "train_dataset, test_dataset = random_split(dataset, [m - int(m / 4), int(m / 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c27d43",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "net = NeuralNetClassifier(\n",
    "    CNN(),\n",
    "    max_epochs=num_epochs,\n",
    "    lr=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    optimizer=optim.Adam,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    device=device,\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "y_train = np.array([np.int64(y) for x, y in iter(train_dataset)])\n",
    "net.fit(train_dataset, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed3ca4",
   "metadata": {},
   "source": [
    "## Post-training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5601ca24",
   "metadata": {},
   "source": [
    "Train/test 75/25 split evaluation (**fast**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d745e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = net.predict(test_dataset)\n",
    "y_test = np.array([y for x, y in iter(test_dataset)])\n",
    "print('Accuracy for {} Dataset: {}%'.format('Test', round(accuracy_score(y_test, y_predict) * 100, 2)))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predict, display_labels=classes)\n",
    "plt.title('Confusion Matrix for {} Dataset'.format('Test'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481914a",
   "metadata": {},
   "source": [
    "K-fold cross-validation (**very slow**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc122d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_score': make_scorer(f1_score, average='weighted'),\n",
    "}\n",
    "y_train = np.array([np.int64(y) for x, y in iter(dataset)])\n",
    "train_sliceable = SliceDataset(dataset)\n",
    "scores = cross_validate(net, train_sliceable, y_train, cv=k, scoring=scoring)\n",
    "print('\\nScores:')\n",
    "print('Accuracy: ', format(scores['test_accuracy']))\n",
    "print('Precision: ', format(scores['test_precision']))\n",
    "print('Recall: ', format(scores['test_recall']))\n",
    "print('F1-measure: ', format(scores['test_f1_score']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
